{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":96164,"databundleVersionId":12993472,"sourceType":"competition"},{"sourceId":251210345,"sourceType":"kernelVersion"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install koolbox scikit-learn==1.5.2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T08:01:00.078212Z","iopub.execute_input":"2025-07-24T08:01:00.078920Z","iopub.status.idle":"2025-07-24T08:01:03.372929Z","shell.execute_reply.started":"2025-07-24T08:01:00.078895Z","shell.execute_reply":"2025-07-24T08:01:03.372164Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.linear_model import Ridge\nfrom lightgbm import LGBMRegressor\nfrom scipy.stats import pearsonr as pr\nfrom xgboost import XGBRegressor\nfrom sklearn.base import clone\nfrom koolbox import Trainer\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport warnings\nimport optuna\nimport joblib\nimport glob\nimport gc\n\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T08:01:04.598851Z","iopub.execute_input":"2025-07-24T08:01:04.599112Z","iopub.status.idle":"2025-07-24T08:01:04.604469Z","shell.execute_reply.started":"2025-07-24T08:01:04.599090Z","shell.execute_reply":"2025-07-24T08:01:04.603725Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_importance = pd.read_csv(\"/kaggle/input/marcus-crypto-analysis/rf_features.csv\")\nselected_features_rfe = pd.read_csv(\"/kaggle/input/marcus-crypto-analysis/rfe_features.csv\")\ntarget_correlations = pd.read_csv(\"/kaggle/input/marcus-crypto-analysis/tc_features.csv\")\nfeature_scores = pd.read_csv(\"/kaggle/input/marcus-crypto-analysis/fs_features.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T08:01:07.619099Z","iopub.execute_input":"2025-07-24T08:01:07.619402Z","iopub.status.idle":"2025-07-24T08:01:07.633639Z","shell.execute_reply.started":"2025-07-24T08:01:07.619381Z","shell.execute_reply":"2025-07-24T08:01:07.633135Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"important_features = {\n    'top_univariate': feature_scores.head(100)['feature'].tolist(),\n    'top_rf_importance': feature_importance.head(100)['feature'].tolist(),\n    'rfe_selected': selected_features_rfe.head(100)['feature'].tolist(),\n    'high_target_corr': target_correlations.head(100)['feature'].tolist()\n}\n\ncommon_features = set(important_features['top_univariate']) & \\\n                 set(important_features['top_rf_importance']) & \\\n                 set(important_features['rfe_selected'])& \\\n                set(important_features['high_target_corr'])\nprint(f\"  Common Features selected by all 4 methods: {(common_features)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T08:01:09.579659Z","iopub.execute_input":"2025-07-24T08:01:09.579998Z","iopub.status.idle":"2025-07-24T08:01:09.585770Z","shell.execute_reply.started":"2025-07-24T08:01:09.579943Z","shell.execute_reply":"2025-07-24T08:01:09.585132Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"common_features=list(common_features)\n\nX_FEATURES = ['bid_qty', 'ask_qty', 'buy_qty', 'sell_qty']+ common_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T08:01:10.784105Z","iopub.execute_input":"2025-07-24T08:01:10.784388Z","iopub.status.idle":"2025-07-24T08:01:10.787713Z","shell.execute_reply.started":"2025-07-24T08:01:10.784367Z","shell.execute_reply":"2025-07-24T08:01:10.786972Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Detect Outliner\n\nReference https://www.kaggle.com/code/isinsuu/drw-autoencoder-mlp-outlier","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom prophet import Prophet\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndef simple_prophet_outlier_detection(df, feature_col, timestamp_col='__index_level_0__'):\n    \"\"\"\n    Simple example of using Prophet to detect outliers in a single feature.\n    \n    The idea: Prophet models the expected behavior of the feature over time.\n    Points that fall far outside Prophet's confidence interval are outliers.\n    \"\"\"\n    print(f\"Detecting outliers in {feature_col} using Prophet...\")\n    \n    # 1. Prepare data for Prophet\n    prophet_df = pd.DataFrame({\n        'ds': df[timestamp_col],\n        'y': df[feature_col]\n    })\n    \n    # Remove obvious bad values\n    prophet_df = prophet_df[np.isfinite(prophet_df['y'])]\n    \n    # Resample to hourly for efficiency (adjust based on your needs)\n    prophet_hourly = prophet_df.set_index('ds').resample('1H').mean().reset_index()\n    prophet_hourly = prophet_hourly.dropna()\n    \n    # 2. Fit Prophet model\n    model = Prophet(\n        changepoint_prior_scale=0.05,  # Low value = less sensitive to outliers\n        interval_width=0.95,  # 95% confidence interval\n        yearly_seasonality=False,\n        weekly_seasonality=True,\n        daily_seasonality=True\n    )\n    \n    model.fit(prophet_hourly)\n    \n    # 3. Generate predictions\n    forecast = model.predict(prophet_hourly)\n    \n    # 4. Identify outliers\n    # Method 1: Points outside confidence interval\n    outliers_ci = (\n        (prophet_hourly['y'] < forecast['yhat_lower']) | \n        (prophet_hourly['y'] > forecast['yhat_upper'])\n    )\n    \n    # Method 2: Points with large standardized residuals\n    residuals = prophet_hourly['y'] - forecast['yhat']\n    residual_std = residuals.std()\n    outliers_residual = np.abs(residuals) > 3 * residual_std\n    \n    # Combine both methods\n    outliers = outliers_ci & outliers_residual\n    \n    # 5. Visualize\n    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n    \n    # Plot 1: Time series with outliers\n    ax1.plot(prophet_hourly['ds'], prophet_hourly['y'], 'b.', alpha=0.5, label='Actual')\n    ax1.plot(forecast['ds'], forecast['yhat'], 'g-', linewidth=2, label='Prophet Fit')\n    ax1.fill_between(forecast['ds'], forecast['yhat_lower'], forecast['yhat_upper'], \n                     alpha=0.2, color='green', label='95% CI')\n    \n    # Highlight outliers\n    outlier_points = prophet_hourly[outliers]\n    ax1.scatter(outlier_points['ds'], outlier_points['y'], \n               color='red', s=100, edgecolor='darkred', linewidth=2, \n               label=f'Outliers ({outliers.sum()})', zorder=10)\n    \n    ax1.set_title(f'Prophet Outlier Detection: {feature_col}')\n    ax1.set_xlabel('Date')\n    ax1.set_ylabel('Value')\n    ax1.legend()\n    ax1.grid(True, alpha=0.3)\n    \n    # Plot 2: Residual distribution\n    ax2.hist(residuals, bins=50, alpha=0.7, color='blue', edgecolor='black')\n    ax2.axvline(x=-3*residual_std, color='red', linestyle='--', label='±3σ threshold')\n    ax2.axvline(x=3*residual_std, color='red', linestyle='--')\n    ax2.set_title('Residual Distribution')\n    ax2.set_xlabel('Residual (Actual - Predicted)')\n    ax2.set_ylabel('Frequency')\n    ax2.legend()\n    ax2.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # 6. Return outlier information\n    outlier_info = {\n        'n_outliers': outliers.sum(),\n        'outlier_pct': outliers.sum() / len(prophet_hourly) * 100,\n        'outlier_timestamps': outlier_points['ds'].tolist(),\n        'outlier_values': outlier_points['y'].tolist(),\n        'residual_std': residual_std\n    }\n    \n    print(f\"Found {outlier_info['n_outliers']} outliers ({outlier_info['outlier_pct']:.2f}%)\")\n    \n    return outlier_info, model, forecast\n\n\n# Quick example for multiple features\ndef detect_outliers_multiple_features(data_path, features_to_check=None):\n    \"\"\"\n    Run outlier detection on multiple features.\n    \"\"\"\n    # Load data\n    if features_to_check is None:\n        # Default to some common features\n        features_to_check = ['volume', 'bid_qty', 'ask_qty', 'buy_qty', 'sell_qty']\n    \n    df = pd.read_parquet(data_path, columns=['__index_level_0__'] + features_to_check)\n    \n    # Ensure timestamp\n    if '__index_level_0__' not in df.columns:\n        df['__index_level_0__'] = pd.date_range('2023-03-01', periods=len(df), freq='T')\n    \n    # Analyze each feature\n    outlier_summary = {}\n    \n    for feature in features_to_check:\n        if feature in df.columns:\n            print(f\"\\n{'='*60}\")\n            outlier_info, model, forecast = simple_prophet_outlier_detection(df, feature)\n            outlier_summary[feature] = outlier_info\n    \n    # Summary plot\n    fig, ax = plt.subplots(figsize=(10, 6))\n    \n    features = list(outlier_summary.keys())\n    outlier_pcts = [outlier_summary[f]['outlier_pct'] for f in features]\n    \n    bars = ax.bar(features, outlier_pcts, color='coral', edgecolor='darkred', linewidth=2)\n    \n    # Highlight high outlier features\n    for i, pct in enumerate(outlier_pcts):\n        if pct > 1.0:  # More than 1% outliers\n            bars[i].set_color('red')\n    \n    ax.set_title('Outlier Percentage by Feature', fontsize=14, fontweight='bold')\n    ax.set_ylabel('Outlier %')\n    ax.set_xlabel('Feature')\n    ax.grid(True, alpha=0.3, axis='y')\n    \n    # Add value labels\n    for bar, pct in zip(bars, outlier_pcts):\n        height = bar.get_height()\n        ax.text(bar.get_x() + bar.get_width()/2., height,\n                f'{pct:.2f}%', ha='center', va='bottom')\n    \n    plt.tight_layout()\n    plt.show()\n    \n    return outlier_summary\n\n\n# Practical example: Using outlier detection for data cleaning\ndef clean_feature_outliers(df, feature_col, outlier_info, method='cap'):\n    \"\"\"\n    Clean outliers from a feature using different methods.\n    \"\"\"\n    # Get outlier timestamps\n    outlier_timestamps = outlier_info['outlier_timestamps']\n    \n    # Create copy\n    df_clean = df.copy()\n    \n    if method == 'remove':\n        # Remove rows with outliers\n        mask = ~df_clean['__index_level_0__'].isin(outlier_timestamps)\n        df_clean = df_clean[mask]\n        print(f\"Removed {len(outlier_timestamps)} rows with outliers\")\n        \n    elif method == 'cap':\n        # Cap outliers at 99th percentile\n        lower_cap = df_clean[feature_col].quantile(0.01)\n        upper_cap = df_clean[feature_col].quantile(0.99)\n        \n        df_clean[feature_col] = df_clean[feature_col].clip(lower=lower_cap, upper=upper_cap)\n        print(f\"Capped {feature_col} to range [{lower_cap:.2f}, {upper_cap:.2f}]\")\n        \n    elif method == 'interpolate':\n        # Replace outliers with interpolated values\n        outlier_mask = df_clean['__index_level_0__'].isin(outlier_timestamps)\n        df_clean.loc[outlier_mask, feature_col] = np.nan\n        df_clean[feature_col] = df_clean[feature_col].interpolate(method='linear')\n        print(f\"Interpolated {len(outlier_timestamps)} outlier values\")\n    \n    return df_clean\n\n\n# Example usage\nif __name__ == \"__main__\":\n    # Example 1: Single feature analysis\n    data_path = '/kaggle/input/drw-crypto-market-prediction/train.parquet'\n    df = pd.read_parquet(data_path, columns=['__index_level_0__', 'volume', 'label'] + X_FEATURES)\n    \n    if '__index_level_0__' not in df.columns:\n        df['__index_level_0__'] = pd.date_range('2023-03-01', periods=len(df), freq='T')\n    \n    # Detect outliers in volume\n    outlier_info, model, forecast = simple_prophet_outlier_detection(df, 'volume')\n    \n    # Example 2: Multiple features\n    outlier_summary = detect_outliers_multiple_features(\n        data_path,\n        X_FEATURES\n    )\n    \n    # Example 3: Clean the data\n    df_clean = df.copy()\n    for feat in X_FEATURES:\n        if feat in outlier_summary:\n            df_clean = clean_feature_outliers(df_clean, feat, outlier_summary[feat], method='cap')\n    print(\"\\nOutlier detection complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T08:01:12.390464Z","iopub.execute_input":"2025-07-24T08:01:12.390784Z","iopub.status.idle":"2025-07-24T08:02:29.229150Z","shell.execute_reply.started":"2025-07-24T08:01:12.390760Z","shell.execute_reply":"2025-07-24T08:02:29.228379Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def reduce_mem_usage(dataframe, dataset):    \n    print('Reducing memory usage for:', dataset)\n    initial_mem_usage = dataframe.memory_usage().sum() / 1024**2\n    \n    for col in dataframe.columns:\n        col_type = dataframe[col].dtype\n\n        c_min = dataframe[col].min()\n        c_max = dataframe[col].max()\n        if str(col_type)[:3] == 'int':\n            if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                dataframe[col] = dataframe[col].astype(np.int8)\n            elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                dataframe[col] = dataframe[col].astype(np.int16)\n            elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                dataframe[col] = dataframe[col].astype(np.int32)\n            elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                dataframe[col] = dataframe[col].astype(np.int64)\n        else:\n            if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                dataframe[col] = dataframe[col].astype(np.float16)\n            elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                dataframe[col] = dataframe[col].astype(np.float32)\n            else:\n                dataframe[col] = dataframe[col].astype(np.float64)\n\n    final_mem_usage = dataframe.memory_usage().sum() / 1024**2\n    print('--- Memory usage before: {:.2f} MB'.format(initial_mem_usage))\n    print('--- Memory usage after: {:.2f} MB'.format(final_mem_usage))\n    print('--- Decreased memory usage by {:.1f}%\\n'.format(100 * (initial_mem_usage - final_mem_usage) / initial_mem_usage))\n\n    return dataframe","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T08:02:29.230399Z","iopub.execute_input":"2025-07-24T08:02:29.230633Z","iopub.status.idle":"2025-07-24T08:02:29.238686Z","shell.execute_reply.started":"2025-07-24T08:02:29.230614Z","shell.execute_reply":"2025-07-24T08:02:29.238060Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===== Feature Engineering =====\ndef feature_engineering(data):\n    #features_df = pd.DataFrame(index=data.index)\n    \n    data['bid_ask_spread_proxy'] = data['ask_qty'] - data['bid_qty']\n    data['total_liquidity'] = data['bid_qty'] + data['ask_qty']\n    data['trade_imbalance'] = data['buy_qty'] - data['sell_qty']\n    data['total_trades'] = data['buy_qty'] + data['sell_qty']\n    \n    data['volume_per_trade'] = data['volume'] / (data['buy_qty'] + data['sell_qty'] + 1e-8)\n    data['buy_volume_ratio'] = data['buy_qty'] / (data['volume'] + 1e-8)\n    data['sell_volume_ratio'] = data['sell_qty'] / (data['volume'] + 1e-8)\n    \n    data['buying_pressure'] = data['buy_qty'] / (data['buy_qty'] + data['sell_qty'] + 1e-8)\n    data['selling_pressure'] = data['sell_qty'] / (data['buy_qty'] + data['sell_qty'] + 1e-8)\n    \n    data['order_imbalance'] = (data['bid_qty'] - data['ask_qty']) / (data['bid_qty'] + data['ask_qty'] + 1e-8)\n    data['order_imbalance_abs'] = np.abs(data['order_imbalance'])\n    data['bid_liquidity_ratio'] = data['bid_qty'] / (data['volume'] + 1e-8)\n    data['ask_liquidity_ratio'] = data['ask_qty'] / (data['volume'] + 1e-8)\n    data['market_depth'] = data['bid_qty'] + data['ask_qty']\n    data['depth_imbalance'] = data['market_depth'] - data['volume']\n\n    data['buy_sell_ratio'] = data['buy_qty'] / (data['sell_qty'] + 1e-8)\n    data['bid_ask_ratio'] = data['bid_qty'] / (data['ask_qty'] + 1e-8)\n    data['volume_liquidity_ratio'] = data['volume'] / (data['bid_qty'] + data['ask_qty'] + 1e-8)\n\n    data['buy_volume_product'] = data['buy_qty'] * data['volume']\n    data['sell_volume_product'] = data['sell_qty'] * data['volume']\n    data['bid_ask_product'] = data['bid_qty'] * data['ask_qty']\n    \n    data['market_competition'] = (data['buy_qty'] * data['sell_qty']) / ((data['buy_qty'] + data['sell_qty']) + 1e-8)\n    data['liquidity_competition'] = (data['bid_qty'] * data['ask_qty']) / ((data['bid_qty'] + data['ask_qty']) + 1e-8)\n    \n    total_activity = data['buy_qty'] + data['sell_qty'] + data['bid_qty'] + data['ask_qty']\n    data['market_activity'] = total_activity\n    data['activity_concentration'] = data['volume'] / (total_activity + 1e-8)\n    \n    data['info_arrival_rate'] = (data['buy_qty'] + data['sell_qty']) / (data['volume'] + 1e-8)\n    data['market_making_intensity'] = (data['bid_qty'] + data['ask_qty']) / (data['buy_qty'] + data['sell_qty'] + 1e-8)\n    data['effective_spread_proxy'] = np.abs(data['buy_qty'] - data['sell_qty']) / (data['volume'] + 1e-8)\n\n    lambda_decay = 0.95\n    ofi = data['buy_qty'] - data['sell_qty']\n    data['order_flow_imbalance_ewm'] = ofi.ewm(alpha=1-lambda_decay).mean()\n\n    data = data.replace([np.inf, -np.inf], np.nan)\n    \n    return data        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T08:02:29.239289Z","iopub.execute_input":"2025-07-24T08:02:29.239539Z","iopub.status.idle":"2025-07-24T08:02:29.249548Z","shell.execute_reply.started":"2025-07-24T08:02:29.239518Z","shell.execute_reply":"2025-07-24T08:02:29.248756Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CFG:\n    train_path = \"/kaggle/input/drw-crypto-market-prediction/train.parquet\"\n    test_path = \"/kaggle/input/drw-crypto-market-prediction/test.parquet\"\n    sample_sub_path = \"/kaggle/input/drw-crypto-market-prediction/sample_submission.csv\"\n\n    target = \"label\"\n    n_folds = 5\n    seed = 42\n\n    run_optuna = True\n    n_optuna_trials = 500","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T08:02:29.250744Z","iopub.execute_input":"2025-07-24T08:02:29.251004Z","iopub.status.idle":"2025-07-24T08:02:29.254611Z","shell.execute_reply.started":"2025-07-24T08:02:29.250989Z","shell.execute_reply":"2025-07-24T08:02:29.253830Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train = df_clean\ntest = pd.read_parquet(CFG.test_path).reset_index(drop=True)\nselected_columns = X_FEATURES+[\"volume\"]\ntrain = train[selected_columns + [CFG.target]]\ntest = test[selected_columns]\n\n# Apply feature engineering\ntrain = feature_engineering(train)\ntest = feature_engineering(test)\n\nto_remove = [\"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\", \"volume\"]\n\ntrain = train.drop(columns=to_remove)\ntest = test.drop(columns=to_remove)\n\ntrain = reduce_mem_usage(train, \"train\")\ntest = reduce_mem_usage(test, \"test\")\n\nX = train.drop(CFG.target, axis=1)\ny = train[CFG.target]\nX_test = test\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T08:02:38.419533Z","iopub.execute_input":"2025-07-24T08:02:38.419806Z","iopub.status.idle":"2025-07-24T08:02:46.797790Z","shell.execute_reply.started":"2025-07-24T08:02:38.419786Z","shell.execute_reply":"2025-07-24T08:02:46.797000Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training Base Models","metadata":{}},{"cell_type":"code","source":"def pearsonr(y_true, y_pred):\n    return pr(y_true, y_pred)[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T08:03:22.098668Z","iopub.execute_input":"2025-07-24T08:03:22.099404Z","iopub.status.idle":"2025-07-24T08:03:22.102774Z","shell.execute_reply.started":"2025-07-24T08:03:22.099377Z","shell.execute_reply":"2025-07-24T08:03:22.101911Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Optuna training Next ","metadata":{}},{"cell_type":"code","source":"lgbm_params = {\n    \"boosting_type\": \"gbdt\",\n    \"colsample_bytree\": 0.5625888953382505,\n    \"learning_rate\": 0.029312951475451557,\n    \"min_child_samples\": 63,\n    \"min_child_weight\": 0.11456572852335424,\n    \"n_estimators\": 126,\n    \"n_jobs\": -1,\n    \"num_leaves\": 37,\n    \"random_state\": 42,\n    \"reg_alpha\": 85.2476527854083,\n    \"reg_lambda\": 99.38305361388907,\n    \"subsample\": 0.450669817684892,\n    \"verbose\": -1\n}\n\nlgbm_goss_params = {\n    \"boosting_type\": \"goss\",\n    \"colsample_bytree\": 0.34695458228489784,\n    \"learning_rate\": 0.031023014900595287,\n    \"min_child_samples\": 30,\n    \"min_child_weight\": 0.4727729225033618,\n    \"n_estimators\": 220,\n    \"n_jobs\": -1,\n    \"num_leaves\": 58,\n    \"random_state\": 42,\n    \"reg_alpha\": 38.665994901468224,\n    \"reg_lambda\": 92.76991677464294,\n    \"subsample\": 0.4810891284493255,\n    \"verbose\": -1\n}\n\nxgb_params = {\n    \"colsample_bylevel\": 0.4778015829774066,\n    \"colsample_bynode\": 0.362764358742407,\n    \"colsample_bytree\": 0.7107423488010493,\n    \"gamma\": 1.7094857725240398,\n    \"learning_rate\": 0.02213323588455387,\n    \"max_depth\": 20,\n    \"max_leaves\": 12,\n    \"min_child_weight\": 16,\n    \"n_estimators\": 1667,\n    \"n_jobs\": -1,\n    \"random_state\": 42,\n    \"reg_alpha\": 39.352415706891264,\n    \"reg_lambda\": 75.44843704068275,\n    \"subsample\": 0.06566669853471274,\n    \"verbosity\": 0\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T08:03:25.374428Z","iopub.execute_input":"2025-07-24T08:03:25.374688Z","iopub.status.idle":"2025-07-24T08:03:25.380274Z","shell.execute_reply.started":"2025-07-24T08:03:25.374668Z","shell.execute_reply":"2025-07-24T08:03:25.379576Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fold_scores = {}\noverall_scores = {}\n\noof_preds = {}\ntest_preds = {}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T08:03:27.103644Z","iopub.execute_input":"2025-07-24T08:03:27.103928Z","iopub.status.idle":"2025-07-24T08:03:27.107450Z","shell.execute_reply.started":"2025-07-24T08:03:27.103908Z","shell.execute_reply":"2025-07-24T08:03:27.106666Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# LightGBM (gbdt)","metadata":{}},{"cell_type":"code","source":"lgbm_trainer = Trainer(\n    LGBMRegressor(**lgbm_params),\n    cv=KFold(n_splits=5, shuffle=False),\n    metric=pearsonr,\n    task=\"regression\",\n    metric_precision=6\n)\n\nlgbm_trainer.fit(X, y)\n\nfold_scores[\"LightGBM (gbdt)\"] = lgbm_trainer.fold_scores\noverall_scores[\"LightGBM (gbdt)\"] = [pearsonr(lgbm_trainer.oof_preds, y)]\noof_preds[\"LightGBM (gbdt)\"] = lgbm_trainer.oof_preds\ntest_preds[\"LightGBM (gbdt)\"] = lgbm_trainer.predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T08:03:29.245930Z","iopub.execute_input":"2025-07-24T08:03:29.246519Z","iopub.status.idle":"2025-07-24T08:04:02.101346Z","shell.execute_reply.started":"2025-07-24T08:03:29.246496Z","shell.execute_reply":"2025-07-24T08:04:02.100725Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# LightGBM (goss)","metadata":{}},{"cell_type":"code","source":"lgbm_goss_trainer = Trainer(\n    LGBMRegressor(**lgbm_goss_params),\n    cv=KFold(n_splits=5, shuffle=False),\n    metric=pearsonr,\n    task=\"regression\",\n    metric_precision=6\n)\n\nlgbm_goss_trainer.fit(X, y)\n\nfold_scores[\"LightGBM (goss)\"] = lgbm_goss_trainer.fold_scores\noverall_scores[\"LightGBM (goss)\"] = [pearsonr(lgbm_goss_trainer.oof_preds, y)]\noof_preds[\"LightGBM (goss)\"] = lgbm_goss_trainer.oof_preds\ntest_preds[\"LightGBM (goss)\"] = lgbm_goss_trainer.predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T08:04:02.102703Z","iopub.execute_input":"2025-07-24T08:04:02.103523Z","iopub.status.idle":"2025-07-24T08:05:01.854250Z","shell.execute_reply.started":"2025-07-24T08:04:02.103496Z","shell.execute_reply":"2025-07-24T08:05:01.853662Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# XGBoost","metadata":{}},{"cell_type":"code","source":"xgb_trainer = Trainer(\n    XGBRegressor(**xgb_params),\n    cv=KFold(n_splits=5, shuffle=False),\n    metric=pearsonr,\n    task=\"regression\",\n    metric_precision=6\n)\n\nxgb_trainer.fit(X, y)\n\nfold_scores[\"XGBoost\"] = xgb_trainer.fold_scores\noverall_scores[\"XGBoost\"] = [pearsonr(xgb_trainer.oof_preds, y)]\noof_preds[\"XGBoost\"] = xgb_trainer.oof_preds\ntest_preds[\"XGBoost\"] = xgb_trainer.predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T08:05:01.857121Z","iopub.execute_input":"2025-07-24T08:05:01.858542Z","iopub.status.idle":"2025-07-24T08:08:31.813259Z","shell.execute_reply.started":"2025-07-24T08:05:01.858520Z","shell.execute_reply":"2025-07-24T08:08:31.812680Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Ensembling with Ridge","metadata":{}},{"cell_type":"code","source":"def plot_weights(weights, title):\n    sorted_indices = np.argsort(weights[0])[::-1]\n    sorted_coeffs = np.array(weights[0])[sorted_indices]\n    sorted_model_names = np.array(list(oof_preds.keys()))[sorted_indices]\n\n    plt.figure(figsize=(10, weights.shape[1] * 0.5))\n    ax = sns.barplot(x=sorted_coeffs, y=sorted_model_names, palette=\"RdYlGn_r\")\n\n    for i, (value, name) in enumerate(zip(sorted_coeffs, sorted_model_names)):\n        if value >= 0:\n            ax.text(value, i, f\"{value:.3f}\", va=\"center\", ha=\"left\", color=\"black\")\n        else:\n            ax.text(value, i, f\"{value:.3f}\", va=\"center\", ha=\"right\", color=\"black\")\n\n    xlim = ax.get_xlim()\n    ax.set_xlim(xlim[0] - 0.1 * abs(xlim[0]), xlim[1] + 0.1 * abs(xlim[1]))\n\n    plt.title(title)\n    plt.xlabel(\"\")\n    plt.ylabel(\"\")\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T08:08:31.814409Z","iopub.execute_input":"2025-07-24T08:08:31.814971Z","iopub.status.idle":"2025-07-24T08:08:31.820735Z","shell.execute_reply.started":"2025-07-24T08:08:31.814947Z","shell.execute_reply":"2025-07-24T08:08:31.820253Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = pd.DataFrame(oof_preds)\nX_test = pd.DataFrame(test_preds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T08:08:31.821425Z","iopub.execute_input":"2025-07-24T08:08:31.821747Z","iopub.status.idle":"2025-07-24T08:08:31.830513Z","shell.execute_reply.started":"2025-07-24T08:08:31.821730Z","shell.execute_reply":"2025-07-24T08:08:31.829835Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"joblib.dump(X, \"oof_preds.pkl\")\njoblib.dump(X_test, \"test_preds.pkl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T08:08:31.831285Z","iopub.execute_input":"2025-07-24T08:08:31.831526Z","iopub.status.idle":"2025-07-24T08:08:31.884779Z","shell.execute_reply.started":"2025-07-24T08:08:31.831512Z","shell.execute_reply":"2025-07-24T08:08:31.884217Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def objective(trial):    \n    params = {\n        \"random_state\": CFG.seed,\n        \"alpha\": trial.suggest_float(\"alpha\", 0, 1),\n        \"tol\": trial.suggest_float(\"tol\", 1e-6, 1e-2),\n        \"fit_intercept\": trial.suggest_categorical(\"fit_intercept\", [True, False]),\n        \"positive\": trial.suggest_categorical(\"positive\", [True, False])\n    }\n\n    trainer = Trainer(\n        Ridge(**params),\n        cv=KFold(n_splits=5, shuffle=False),\n        metric=pearsonr,\n        task=\"regression\",\n        verbose=False\n    )\n    trainer.fit(X, y)\n    \n    return pearsonr(trainer.oof_preds, y)\n\nif CFG.run_optuna:\n    sampler = optuna.samplers.TPESampler(seed=CFG.seed, multivariate=True, n_startup_trials=CFG.n_optuna_trials // 10)\n    study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n    study.optimize(objective, n_trials=CFG.n_optuna_trials, n_jobs=-1, catch=(ValueError,))\n    best_params = study.best_params\n\n    ridge_params = {\n        \"random_state\": CFG.seed,\n        \"alpha\": best_params[\"alpha\"],\n        \"tol\": best_params[\"tol\"],\n        \"fit_intercept\": best_params[\"fit_intercept\"],\n        \"positive\": best_params[\"positive\"]\n    }\nelse:\n    ridge_params = {\n        \"random_state\": CFG.seed,\n        'alpha': 0.9999400497591444, 'tol': 0.00943871628637141, 'fit_intercept': False, 'positive': True}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T08:08:39.402268Z","iopub.execute_input":"2025-07-24T08:08:39.402577Z","iopub.status.idle":"2025-07-24T08:15:16.040110Z","shell.execute_reply.started":"2025-07-24T08:08:39.402558Z","shell.execute_reply":"2025-07-24T08:15:16.039361Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ridge_trainer = Trainer(\n    Ridge(**ridge_params),\n    cv=KFold(n_splits=5, shuffle=False),\n    metric=pearsonr,\n    task=\"regression\",\n    metric_precision=6\n)\n\nridge_trainer.fit(X, y)\n\nfold_scores[\"Ridge (ensemble)\"] = ridge_trainer.fold_scores\noverall_scores[\"Ridge (ensemble)\"] = [pearsonr(ridge_trainer.oof_preds, y)]\nridge_test_preds = ridge_trainer.predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T08:15:47.901977Z","iopub.execute_input":"2025-07-24T08:15:47.902615Z","iopub.status.idle":"2025-07-24T08:15:48.754147Z","shell.execute_reply.started":"2025-07-24T08:15:47.902590Z","shell.execute_reply":"2025-07-24T08:15:48.753356Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ridge_coeffs = np.zeros((1, X.shape[1]))\nfor m in ridge_trainer.estimators:\n    ridge_coeffs += m.coef_\nridge_coeffs = ridge_coeffs / len(ridge_trainer.estimators)\n\nplot_weights(ridge_coeffs, \"Ridge Coefficients\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T08:19:43.476807Z","iopub.execute_input":"2025-07-24T08:19:43.477081Z","iopub.status.idle":"2025-07-24T08:19:43.590810Z","shell.execute_reply.started":"2025-07-24T08:19:43.477061Z","shell.execute_reply":"2025-07-24T08:19:43.590010Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sub = pd.read_csv(CFG.sample_sub_path)\nsub[\"prediction\"] = test_preds[\"XGBoost\"] \nsub.to_csv(f\"xgb.csv\", index=False)\nsub.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T08:19:10.190171Z","iopub.execute_input":"2025-07-24T08:19:10.190913Z","iopub.status.idle":"2025-07-24T08:19:11.342010Z","shell.execute_reply.started":"2025-07-24T08:19:10.190887Z","shell.execute_reply":"2025-07-24T08:19:11.341226Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sub[\"prediction\"] = test_preds\nsub.to_csv(f\"sub_ridge_{overall_scores['Ridge (ensemble)'][0]:.6f}.csv\", index=False)\nsub.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T08:16:49.003403Z","iopub.execute_input":"2025-07-24T08:16:49.004125Z","iopub.status.idle":"2025-07-24T08:16:49.011911Z","shell.execute_reply.started":"2025-07-24T08:16:49.004101Z","shell.execute_reply":"2025-07-24T08:16:49.011219Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fold_scores","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T08:20:01.861501Z","iopub.execute_input":"2025-07-24T08:20:01.861769Z","iopub.status.idle":"2025-07-24T08:20:01.869873Z","shell.execute_reply.started":"2025-07-24T08:20:01.861748Z","shell.execute_reply":"2025-07-24T08:20:01.869081Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Results","metadata":{}},{"cell_type":"code","source":"fold_scores = pd.DataFrame(fold_scores)\n#overall_scores = pd.DataFrame(overall_scores).transpose().sort_values(by=0, ascending=False)\norder = overall_scores.index.tolist()\n\nmin_score = overall_scores.values.flatten().min()\nmax_score = overall_scores.values.flatten().max()\npadding = (max_score - min_score) * 0.5\nlower_limit = min_score - padding\nupper_limit = max_score + padding\n\nfig, axs = plt.subplots(1, 2, figsize=(15, fold_scores.shape[1] * 0.5))\n\nboxplot = sns.boxplot(data=fold_scores, order=order, ax=axs[0], orient=\"h\", color=\"grey\")\naxs[0].set_title(f\"Fold Score\")\naxs[0].set_xlabel(\"\")\naxs[0].set_ylabel(\"\")\n\nbarplot = sns.barplot(x=overall_scores.values.flatten(), y=overall_scores.index, ax=axs[1], color=\"grey\")\naxs[1].set_title(f\"Overall Score\")\naxs[1].set_xlabel(\"\")\naxs[1].set_xlim(left=lower_limit, right=upper_limit)\naxs[1].set_ylabel(\"\")\n\nfor i, (score, model) in enumerate(zip(overall_scores.values.flatten(), overall_scores.index)):\n    color = \"cyan\" if \"ensemble\" in model.lower() else \"grey\"\n    barplot.patches[i].set_facecolor(color)\n    boxplot.patches[i].set_facecolor(color)\n    barplot.text(score, i, round(score, 6), va=\"center\")\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T08:20:18.531864Z","iopub.execute_input":"2025-07-24T08:20:18.532139Z","iopub.status.idle":"2025-07-24T08:20:18.793929Z","shell.execute_reply.started":"2025-07-24T08:20:18.532119Z","shell.execute_reply":"2025-07-24T08:20:18.793185Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}